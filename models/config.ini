# Archivo de Configuración (config.ini) - v5.7 Optimizado GPU/CPU
# Compatible con train.py v5.7
# Cambios: Modelo=lgbm, device=gpu, SMOTE=True, n_jobs=-1

# --- Secciones para carga de datos ---
[paths]
csv_path = data/SS7 y Diameter especificamente/synthetic_dataset_v5.csv

[validation]
imsi_column_name = c_imsi
timestamp_column_name = c_timestamp
required_columns = c_imsi, c_timestamp, label
imsi_length = 15
timestamp_format =

[processing]
remove_invalid_rows = True
remove_duplicates = True
duplicate_subset_columns =

# --- Parámetros COMUNES a todos los modelos ---
[common_params]
random_state = 42
cv_folds = 3
# Mantener o reducir a 3 si aún es lento
# --- OPTIMIZADO: Usar todos los cores CPU ---
n_jobs = -1
# --- Activado SMOTE (Asegúrate que imblearn esté actualizado o train.py modificado) ---
use_smote = True
use_gridsearch = False
use_randomsearch = True
n_iter = 20  
# Mantener o reducir (e.g., 25-30) para acelerar búsqueda
classification_threshold = 0.5
target_col = label

# --- Selección de modelo ---
[model]
# --- OPTIMIZADO: Cambiado a LightGBM para usar GPU ---
model_type = xgb
# Modelos: rf, lgbm, xgb
# --- Parámetros FIJOS por modelo ---
# Usados si use_randomsearch = False, o como base.

[rf_params] # Mantenidos por si cambias model_type
n_estimators = 150
max_depth = None
class_weight = None 
# SMOTE activado
min_samples_split = 10
min_samples_leaf = 5

[xgb_params] # Mantenidos por si cambias model_type
# Se usan si use_randomsearch = False
n_estimators = 150
learning_rate = 0.1
max_depth = 6
subsample = 0.8
colsample_bytree = 0.8
gamma = 0.1
scale_pos_weight = 1.0 
# SMOTE activado
# --- OPTIMIZADO GPU (alternativa si usas xgb) ---
eval_metric = auc  
# ✅ Define aquí la métrica
tree_method = gpu_hist

[lgbm_params]
n_estimators = 200
learning_rate = 0.05
num_leaves = 31
min_child_samples = 20
subsample = 0.8
colsample_bytree = 0.8
class_weight = None 
# SMOTE activado
# --- OPTIMIZADO: Usar GPU ---
device = gpu
# early_stopping_rounds = 10 # Puedes añadirlo aquí si quieres ES fijo

# --- Distribuciones para RandomizedSearchCV ---
# --- Rangos Ampliados (ajusta n_iter si es muy lento) ---

[rf_param_dist] # Mantenidos por si cambias model_type
n_estimators = randint(100, 700)
max_depth = [None, 10, 20, 30, 40]
min_samples_split = randint(2, 30)
min_samples_leaf = randint(1, 20)
class_weight = [None] # SMOTE activado

[xgb_param_dist] # Mantenidos por si cambias model_type
# Rangos o distribuciones de valores que RandomizedSearchCV probará si use_randomsearch = True
n_estimators = randint(100, 800)
learning_rate = uniform(0.01, 0.2)
max_depth = randint(3, 12)
subsample = uniform(0.6, 0.4)
colsample_bytree = uniform(0.5, 0.5)
gamma = uniform(0, 0.8)
scale_pos_weight = [1.0] # SMOTE activado
# --- OPTIMIZADO GPU (alternativa si usas xgb) ---
tree_method = ['gpu_hist']

[lgbm_param_dist]
n_estimators = randint(150, 400)
learning_rate = uniform(0.01, 0.2)
num_leaves = randint(20, 60)
min_child_samples = randint(10, 50)
subsample = uniform(0.5, 0.5)
colsample_bytree = uniform(0.5, 0.5)
class_weight = [None] # SMOTE activado
# --- OPTIMIZADO: Usar GPU también en la búsqueda ---
device = ['gpu']

# --- Configuración MLflow ---
[mlflow]
# Añadir sufijo GPU al nombre del experimento
experiment_name = FraudDetection_{model_type}_Optimized_v5.7_SMOTE_GPU
register_models = True

# --- Configuración de Evaluación ---
[evaluation]
thresholds_to_test = [0.3, 0.4, 0.5, 0.6]
early_stopping_rounds = 10 # Puedes ponerlo aquí si quieres activarlo para fit directo/final